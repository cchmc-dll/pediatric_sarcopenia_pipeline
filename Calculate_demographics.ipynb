{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook to convert  Dicom files from Ambra to NIFTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dir(target_dir):\n",
    "    with os.scandir(target_dir) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file() or entry.is_symlink():\n",
    "                os.remove(entry.path)\n",
    "            elif entry.is_dir():\n",
    "                shutil.rmtree(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input/output directories\n",
    "os.chdir('/home/jovyan')\n",
    "cwd = os.getcwd()\n",
    "dir_MC =cwd+'/UPLOAD'\n",
    "dir_train = cwd+'/CCHMC_NIFTI'\n",
    "dirs_MC = next(os.walk(dir_MC))[1]\n",
    "dirs_train = next(os.walk(dir_train))[1]\n",
    "print(len(dirs_train),len(dirs_MC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some handy functions for creating dicom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_MC[:] = np.unique([x for x in dirs_MC if not x.startswith('.')])\n",
    "dirs_train[:] = np.unique([x for x in dirs_train if not x.startswith('.')])\n",
    "dirs_testMC = [t for t in dirs_MC if t not in dirs_train]\n",
    "dirs_trainMC = [t for t in dirs_MC if t in dirs_train]\n",
    "# seqs = list()\n",
    "# for d in dirs:\n",
    "#     #match = re.sub('\\d+$','',d) # Pattern for Duke studies\n",
    "#     match = re.sub('\\d*_\\d*$|\\d*$|\\d*_b$','',d) # Pattern for UCSD studies\n",
    "#     if match:\n",
    "#         seqs.append(match)\n",
    "# unique_seqs = np.unique(seqs)\n",
    "\n",
    "print('MC studies',' CCHMC train',' CCHMC test in MC',' CCHMC train in MC')\n",
    "print(len(dirs_MC),' ',len(dirs_train),' ',len(dirs_testMC),' ',len(dirs_trainMC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV with patient details\n",
    "df = pd.read_csv('patient_details.csv',index_col=False,encoding='latin-1')\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of entries in patient_details.csv', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(df['Field'])\n",
    "a = df['Field'].value_counts()\n",
    "a.get(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate demographics for a list of patients\n",
    "def calculate_demographics(pats,df,indexname):\n",
    "    df_pats = df[df['Key'].isin(pats)]\n",
    "    df_pats = df_pats.drop_duplicates(subset=['Key'],keep='first')\n",
    "    \n",
    "#     duplicateRowsDF = df_pats[df_pats.duplicated(['Key'])]\n",
    "#     if duplicateRowsDF is not None:\n",
    "#         display(duplicateRowsDF)\n",
    "    \n",
    "    total_items = len(df_pats)\n",
    "    mean_weight = df_pats[\"WEIGHT\"].mean()\n",
    "    mean_height = df_pats[\"HEIGHT\"].mean()\n",
    "    mean_age = df_pats[\"Age (DOS)\"].mean()\n",
    "    mean_BMI = df_pats[\"BMI\"].mean()\n",
    "    \n",
    "    std_weight = df_pats[\"WEIGHT\"].std()\n",
    "    std_height = df_pats[\"HEIGHT\"].std()\n",
    "    std_age = df_pats[\"Age (DOS)\"].std()\n",
    "    std_BMI = df_pats[\"BMI\"].std()\n",
    "    \n",
    "    age = \"{:.1f}\".format(mean_age) +  u\" \\u00B1 \" + \"{:.1f}\".format(std_age) \n",
    "    weight = \"{:.1f}\".format(mean_weight) +  u\" \\u00B1 \" + \"{:.1f}\".format(std_weight) \n",
    "    height = \"{:.1f}\".format(mean_height) +  u\" \\u00B1 \" + \"{:.1f}\".format(std_height) \n",
    "    bmi = \"{:.1f}\".format(mean_BMI) +  u\" \\u00B1 \" + \"{:.1f}\".format(std_BMI) \n",
    "    \n",
    "    \n",
    "    females = df_pats['GENDER'].value_counts().get('Female')\n",
    "    whites =  df_pats['RACE'].value_counts().get('WHITE')\n",
    "    GEs =  df_pats['Vendor'].value_counts().get('GE MEDICAL SYSTEMS')\n",
    "    Field_3s = df_pats['Field'].value_counts().get(3)\n",
    "    \n",
    "    \n",
    "    return [indexname,total_items,age,height,weight,females,whites,GEs,Field_3s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dirs_trainMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [dirs_MC,dirs_train,dirs_testMC,dirs_trainMC]\n",
    "datasets = ['Phase1 CCHMC data','CCHMC train data','CCHMC test in Phase1','CCHMC train in Phase1']\n",
    "out_df=pd.DataFrame(columns=['Dataset','N','Age','Height','Weight','Females','Whites','GE','Field_3T'])\n",
    "for i in range(len(datasets)):\n",
    "    out = calculate_demographics(dirs[i],df,datasets[i])\n",
    "    out_df.loc[i] = out\n",
    "\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('CCHMC_demographic_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = pd.DataFrame(columns=['Exams used for Training','Exams used for Testing'])\n",
    "\n",
    "split_df['Exams used for Testing'] = dirs_testMC\n",
    "print(len(split_df))\n",
    "dirs_trainMC2 = dirs_trainMC.copy()\n",
    "dirs_trainMC2.append('   ')\n",
    "dirs_trainMC2.append('   ')\n",
    "print(len(dirs_trainMC2),len(dirs_trainMC))\n",
    "split_df['Exams used for Training'] = dirs_trainMC2\n",
    "\n",
    "split_df.to_csv('CCHMC_phase1_train_test_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MultiCenterLS study names from processed CCHMC DICOMs and match with local IDs (ELAST-999) for internal use\n",
    "dir_dcm = os.path.join(cwd,'UPLOAD')\n",
    "pats = os.listdir(dir_dcm)\n",
    "from pydicom import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extmap = pd.DataFrame(columns=['Key','ExternalID'])\n",
    "for i,pat in enumerate(pats):\n",
    "    MR_path = os.path.join(dir_dcm,pat,'T2')\n",
    "    MR_file = os.path.join(MR_path,os.listdir(MR_path)[0])\n",
    "    #print(MR_file)\n",
    "    t2 = read_file(MR_file)\n",
    "    df_extmap.loc[i] = [t2.PatientID, t2.PatientName]\n",
    "df_extmap.to_csv('CCHMC_phase1_internal_external_IDmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_extmap)\n",
    "list(df_extmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DSC = pd.read_csv('CCHMC_isensee_results_151pats_32.csv',index_col=False,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DSC = df_DSC[['ID','DSC']]\n",
    "df_DSC.columns = ['Key','DSC']\n",
    "list(df_DSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_extmap.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_DSC.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DSC_extmap = df_DSC.merge(df_extmap,on=['Key'],how='inner')\n",
    "len(df_DSC_extmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DSC_extmap = df_DSC_extmap[['Key','ExternalID','DSC']]\n",
    "df_DSC_extmap.to_csv('CCHMC_isensee_results_151pats_32_wexternalID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
