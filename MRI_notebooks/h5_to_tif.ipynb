{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Segment Skeletal Muscle Area from MRI images (TIFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/smipipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/tf/smipipeline')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import get_ipython\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "import tables\n",
    "from MRI_notebooks.TIF_loader import mri_TIF_loader\n",
    "from unet3d.normalize import normalize_data_storage_2D\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    " \n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# Custom functions\n",
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):        \n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/smipipeline\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "data = '/tf/data'\n",
    "pickles = '/tf/pickles'\n",
    "models = '/tf/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l3_finder': {'cache_dir': '/tf/_cache/',\n",
      "               'cache_intermediate_results': True,\n",
      "               'model_path_dir': '/tf/models/l3/cv_final',\n",
      "               'new_tim_dicom_dir_structure': True,\n",
      "               'output_directory': '/tf/output/cv_poorl3/l3',\n",
      "               'overwrite': True,\n",
      "               'save_plots': True,\n",
      "               'show_plots': False,\n",
      "               'tif_dir': '/tf/data/sarcopeniaMR_L3_TIF'},\n",
      " 'muscle_segmentor': {'input_directory': '/tf/data/sarcopeniaMR_L3_TIF',\n",
      "                      'output_directory': '/tf/data/sarcopeniaMR_L3_h5',\n",
      "                      'sma_config_args_file': '/tf/smipipeline/config/mri/sma_mri_preproc.args'}}\n"
     ]
    }
   ],
   "source": [
    "# Import modules and config file\n",
    "configfile = os.path.join(cwd,'config/mri/run_preproc_mri.json')\n",
    "with open(configfile, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess config to convert tif to hdf5 file for training\n",
    "config = config['muscle_segmentor']\n",
    "##\n",
    "config[\"input_type\"] = \"Image\"\n",
    "config[\"input_shape\"] = (256,256)\n",
    "config[\"input_images\"] = \"/tf/data\" #config['input_directory']\n",
    "config[\"image_format\"] = \"TIF\" # or \"NIFTI\"\n",
    "config[\"slice_number\"] = 0 # Use this if you have a stacked TIF and want only one slice for 2D problems.\n",
    "                           # slice number goes from 0 to length of Stack\n",
    "config['use_middle_image'] = False\n",
    "\n",
    "config[\"output_file\"] = \"combined_aug3_205_fixed.h5\"\n",
    "config[\"output_directory\"] = '/tf/data/combined_aug3_205'\n",
    "\n",
    "config[\"overwrite\"] = 1\n",
    "config[\"problem_type\"] = \"Segmentation\"\n",
    "config[\"image_modalities\"] = [\"CT\"]\n",
    "config[\"image_masks\"] = [\"MASK\" ] #[\"Label\"]   # For Image Masks, will serve as label for segmentation problems\n",
    "config[\"n_channels\"] = 0            # All image channels that will be used as input, image_mask can be input for classification problems and output for segmentation problems.\n",
    "\n",
    "config[\"clinical_truthname\"] =  None # For CSV File\n",
    "config[\"normalize\"] = True\n",
    "config['normalize_on_load'] = True\n",
    "config[\"invert_image\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clinical_truthname': None,\n",
      " 'image_format': 'TIF',\n",
      " 'image_masks': ['MASK'],\n",
      " 'image_modalities': ['CT'],\n",
      " 'input_directory': '/tf/data/sarcopeniaMR_L3_TIF',\n",
      " 'input_images': '/tf/data',\n",
      " 'input_shape': (256, 256),\n",
      " 'input_type': 'Image',\n",
      " 'invert_image': True,\n",
      " 'n_channels': 0,\n",
      " 'normalize': True,\n",
      " 'normalize_on_load': True,\n",
      " 'output_directory': '/tf/data/combined_aug3_205',\n",
      " 'output_file': 'combined_aug3_205_fixed.h5',\n",
      " 'overwrite': 1,\n",
      " 'problem_type': 'Segmentation',\n",
      " 'slice_number': 0,\n",
      " 'sma_config_args_file': '/tf/smipipeline/config/mri/sma_mri_preproc.args',\n",
      " 'use_middle_image': False}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set overwrite to false when extracting imags from h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['overwrite'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_loader(config,problem_type,input_images):\n",
    "    return mri_TIF_loader(\n",
    "                problem_type,\n",
    "                input_images,\n",
    "                config[\"input_shape\"],\n",
    "                config[\"image_modalities\"],\n",
    "                config[\"image_masks\"],\n",
    "                config['slice_number'],config['invert_image'],config['normalize_on_load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if Input Folders are defined\n",
    "try:\n",
    "    input_type = config[\"input_type\"]\n",
    "except:\n",
    "    print(\"Error: Input type for preprocessing not defined | \\t Set  config[\\\"input_type\\\"] to \\\"Image\\\", \\\"Clinical\\\" or \\\"Both\\\" \\n\")\n",
    "    \n",
    "input_images = config[\"input_images\"]\n",
    "input_clinical = None\n",
    "if (input_type == \"Image\" or input_type == \"Both\"):\n",
    "    try:\n",
    "        input_images = os.path.abspath(config[\"input_images\"])\n",
    "    except:\n",
    "        print(\"Error: Input Image Folder for preprocessing not defined | \\t Set config[\\\"input_images\\\"] \\n\")\n",
    "\n",
    "if (input_type == \"Clinical\" or input_type == \"Both\"):\n",
    "    try:\n",
    "        input_clinical = os.path.abspath(config[\"input_clinical\"])\n",
    "    except:\n",
    "        print(\"Error: Input Clinical Folder with .csv for preprocessing not defined | \\t Set config[\\\"input_clinical\\\"] \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Check if the Output File is defined\n",
    "try:\n",
    "    output_file = os.path.abspath(os.path.join(config[\"output_directory\"], config[\"output_file\"]))\n",
    "except:\n",
    "    print(\"Error: Input type for preprocessing not defined | \\t Set  config[\\\"input_type\\\"] to \\\"Image\\\",\\\"Clinical\\\" or \\\"Both\\\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening h5 file in Read mode...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check if Output file already exists, If it exists, require user permission to overwrite\n",
    "if 'overwrite' in config:\n",
    "    overwrite = config[\"overwrite\"]\n",
    "elif os.path.exists(output_file):\n",
    "    overwrite = input(\"Output file exists, do you want to overwrite? (y/n) \\n\")\n",
    "    overwrite = True if overwrite == 'y' else False   \n",
    "\n",
    "    # Open the hdf5 file\n",
    "if overwrite:\n",
    "    print(\"Opening h5 file in Write mode...\")\n",
    "    hdf5_file = tables.open_file(output_file, mode='w')\n",
    "else:\n",
    "    print(\"Opening h5 file in Read mode...\")\n",
    "    hdf5_file = tables.open_file(output_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type is:  Segmentation\n",
      "Input Type is:  Image\n",
      "Input Images is:  /tf/data\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check problem specific parameters are defined\n",
    "problem_type = config['problem_type']\n",
    "print('Problem type is: ', problem_type)\n",
    "print('Input Type is: ', input_type)\n",
    "print('Input Images is: ', input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert Exams to hdf5 \n",
    "#  Load Imaging Data\n",
    "image_loader = get_image_loader(config,problem_type,input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MRI_notebooks.TIF_loader.mri_TIF_loader object at 0x7f73ac2b87f0>\n"
     ]
    }
   ],
   "source": [
    "print(image_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subjects in h5 file 7\n"
     ]
    }
   ],
   "source": [
    "subject_ids_final = image_loader.get_sample_ids()\n",
    "print(\"Total number of subjects in h5 file\", len(subject_ids_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_modalities = config['image_modalities']\n",
    "data_file =hdf5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_index,subject in enumerate(subject_ids_final):\n",
    "    output_dir = os.path.join(config['output_directory'],subject)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    test_data = np.asarray([data_file.root.imdata[data_index]])\n",
    "    for i, modality in enumerate(training_modalities):\n",
    "        img = test_data[0,i]\n",
    "        image = Image.fromarray(test_data[0, i])\n",
    "        image.save(os.path.join(output_dir, \"data_{0}.TIF\".format(modality)))\n",
    "\n",
    "    truth = data_file.root.truth[data_index][0].astype(np.float32)\n",
    "    test_truth = Image.fromarray(truth)\n",
    "    test_truth.save(os.path.join(output_dir, \"truth.TIF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
