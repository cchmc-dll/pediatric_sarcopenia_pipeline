{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import get_ipython\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "# Custom modules for debugging\n",
    "from SliceViewer import ImageSliceViewer3D, ImageSliceViewer3D_1view,ImageSliceViewer3D_2views\n",
    "from investigate import *\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", 10)\n",
    "      \n",
    "import json\n",
    "from run_sma_experiment import find_l3_images,output_images\n",
    "import pprint\n",
    "from L3_finder import *\n",
    "\n",
    "# Custom functions\n",
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):        \n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('tb', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "data = '/tf/data'\n",
    "pickles = '/tf/pickles/v5_8pts'\n",
    "pickles_old = '/tf/pickles/'\n",
    "models = '/tf/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules and config file\n",
    "configfile = os.path.join(cwd,'config/debug_ES/v5_run_prediction_CV_poorl3.json')\n",
    "with open(configfile, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Process final images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Load each study into subject object\n",
    "<br>\n",
    "Subject object defined in L3finder.ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['l3_finder']['new_tim_dicom_dir_structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "print(\"Finding subjects\")\n",
    "\n",
    "subjects = list(\n",
    "    find_subjects(\n",
    "        config['l3_finder'][\"dicom_dir\"],\n",
    "        new_tim_dir_structure=config['l3_finder']['new_tim_dicom_dir_structure']\n",
    "    )\n",
    ")\n",
    "\n",
    "print('Subjects found: ', len(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-3 - check if there are subjects with multiple folders (studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find series images\n",
    "print(\"Finding series\")\n",
    "series = list(flatten(tqdm((s.find_series() for s in subjects),total=len(subjects))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of series found: \", len(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sagittal_series, axial_series, excluded_series = separate_series(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of valid pats: \", len(subjects))\n",
    "print(\"Length of sagittal series\", len(sagittal_series))\n",
    "print(\"Length of axial series\", len(axial_series))\n",
    "print(\"Length of excluded series\", len(excluded_series))\n",
    "print(\"Length of all series in dataset\", len(series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure each subject has at the max only 1 axial and 1 sagittal series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_ids = [ax.subject.id_ for ax in axial_series]\n",
    "sag_ids = [sag.subject.id_ for sag in sagittal_series]\n",
    "\n",
    "def find_duplicates(id_list):\n",
    "    uniques = []\n",
    "    duplicates = []\n",
    "    for ids in id_list:\n",
    "        if ids in uniques:\n",
    "            duplicates.append(ids)\n",
    "        else:\n",
    "            uniques.append(ids)\n",
    "            \n",
    "    return uniques,duplicates\n",
    "\n",
    "\n",
    "ax_u,ax_d = find_duplicates(ax_ids)\n",
    "sag_u,sag_d = find_duplicates(sag_ids)\n",
    "\n",
    "print('Ax duplicates: ', ax_d)\n",
    "print('Sag duplicates: ', sag_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the series objects to investigate\n",
    "ax_d_series = [ax for ax in axial_series if ax.subject.id_ in ax_d]\n",
    "sag_d_series = [ax for ax in sagittal_series if ax.subject.id_ in ax_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('axials with duplicate: ',len(ax_d_series))\n",
    "print('sagittals with duplicate: ',len(sag_d_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# df_dl= load_object(os.path.join(pickles_old,'df_final.pkl'))\n",
    "# display(df_dl[df_dl['ID']==ax_d[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Missing Sagittals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default code filters 0.5mm slices, but I am letting them pass by setting it to 0\n",
    "constructed_sagittals = construct_series_for_subjects_without_sagittals(\n",
    "        subjects, sagittal_series, axial_series,thickness_filter=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "        \"Series separated\\n\",\n",
    "        len(sagittal_series), \"sagittal series.\",\n",
    "        len(axial_series), \"axial series.\",\n",
    "        len(excluded_series), \"excluded series.\",\n",
    "        len(constructed_sagittals), \"constructed series.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagittal_series.extend(constructed_sagittals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(axial_series,os.path.join(pickles,'axial_curated.pkl'))\n",
    "save_object(sagittal_series,os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating sagittal MIPS\")\n",
    "mips = create_sagittal_mips_from_series(\n",
    "        many_series=sagittal_series,\n",
    "        cache_dir=config['l3_finder'].get(\"cache_dir\", None),\n",
    "        cache=config['l3_finder'].get(\"cache_intermediate_results\", False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(mips,os.path.join(pickles,'mips.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mips = load_object(os.path.join(pickles,'mips.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing Images\")\n",
    "preprocessed_images = preprocess_images(mips)\n",
    "\n",
    "# Sagittal mip is redundant, get rid just use preprocessed images\n",
    "sagittal_mips = [SagittalMIP(i) for i in preprocessed_images]\n",
    "\n",
    "print(\"Separate heights for better batching\")\n",
    "mips_by_dimension = group_mips_by_dimension(sagittal_mips)\n",
    "print(\"Dimensions in set:\", mips_by_dimension.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(mips_by_dimension,os.path.join(pickles,'mips_by_dimension.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find L3 - step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mips_by_dimension = load_object(os.path.join(pickles,'mips_by_dimension.pkl'))\n",
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))\n",
    "sagittal_series = load_object(os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all models in model path dir\n",
    "models_dir = config['l3_finder']['model_path_dir']\n",
    "\n",
    "# Get all models in models dir\n",
    "models_list = sorted([f for f in os.listdir(models_dir) if f.endswith('.h5')])\n",
    "print(models_list)\n",
    "folds = len(models_list)\n",
    "\n",
    "for fold in range(folds):\n",
    "    model_path = os.path.join(models_dir,models_list[fold])\n",
    "    print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runname = 'CV_poorl3'\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(folds):\n",
    "        model_path = os.path.join(models_dir,models_list[fold])\n",
    "        print(\"Making predictions for fold \", fold, 'Path: ', model_path)\n",
    "        prediction_results = []\n",
    "        prediction_errors = []\n",
    "        for dimension, sagittal_mips in mips_by_dimension.items():\n",
    "            dim_group_results,errors = make_predictions_for_sagittal_mips(\n",
    "                sagittal_mips,\n",
    "                model_path=model_path,\n",
    "                shape=dimension\n",
    "            )\n",
    "            prediction_results.extend(dim_group_results)\n",
    "            prediction_errors.extend(errors)\n",
    "\n",
    "        # Save prediction results\n",
    "        pred_results_file = 'prediction_results_' + str(fold) + '_' +  runname + '.pkl'\n",
    "        pred_errors_file = 'prediction_errors_' + str(fold) + '_' +  runname + '.pkl'\n",
    "        save_object(prediction_results,os.path.join(pickles,pred_results_file))\n",
    "        save_object(prediction_errors,os.path.join(pickles,pred_errors_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save l3 prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(axial_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction_results pickle files\n",
    "runname = 'CV_poorl3'\n",
    "\n",
    "output_dir = config[\"l3_finder\"][\"output_directory\"]\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "prediction_results_list = sorted([f for f in os.listdir(pickles) if (f.startswith('prediction_results_') and f.endswith(runname+'.pkl'))])\n",
    "folds = len(prediction_results_list)\n",
    "print(folds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(folds):\n",
    "        pred_file = os.path.join(pickles,prediction_results_list[fold])\n",
    "        prediction_results = load_object(pred_file)\n",
    "        print('Total predictions: ',len(prediction_results))\n",
    "        print('Building L3 images for fold: ', fold)\n",
    "        l3_images = build_l3_images(axial_series, prediction_results)\n",
    "        print('Total images: ',len(l3_images))\n",
    "        # Don't run this unless you have new L3 results\n",
    "        print(\"Outputting L3 images for fold: \", fold)\n",
    "        # Clears pixel data from memory aafter outputting\n",
    "        output_dir = os.path.join(config[\"l3_finder\"][\"output_directory\"],str(fold))\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        l3_images = output_images(\n",
    "        l3_images,\n",
    "        args=dict(\n",
    "            output_directory=output_dir,\n",
    "            should_plot=config[\"l3_finder\"][\"show_plots\"],\n",
    "            should_overwrite=config[\"l3_finder\"][\"overwrite\"],\n",
    "            should_save_plots=config[\"l3_finder\"][\"save_plots\"]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mean L3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from L3_finder import L3Image\n",
    "from l3finder import ingest\n",
    "\n",
    "from compare_best_to_manual_l3_and_seg import MinimalPrediction, MinimalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_l3_predictions(l3_prediction_dir,nfolds):\n",
    "    subject_id_col = 0\n",
    "    pred_in_px_col = 1\n",
    "    predictions = defaultdict(list)\n",
    "\n",
    "    for fold_index in range(0, nfolds):\n",
    "        csv_dir = os.path.join(l3_prediction_dir,str(fold_index))\n",
    "        csv_path = Path(csv_dir,'l3_prediction_results.csv')\n",
    "        with open(csv_path) as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            next(reader)\n",
    "\n",
    "            for row in reader:\n",
    "                subid = row[subject_id_col].split('-')[0]\n",
    "                predictions[subid].append(float(row[pred_in_px_col]))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def calc_mean_predictions(all_predictions: defaultdict):\n",
    "    result = {}\n",
    "    for subject_id, prediction_list in all_predictions.items():\n",
    "        result[subject_id] = np.mean(prediction_list)\n",
    "    return result\n",
    "\n",
    "def find_subjects_w_preds(predictions, all_subjects):\n",
    "    subject_ids_w_preds = set(predictions.keys())\n",
    "    return [s for s in all_subjects if s.id_ in subject_ids_w_preds]\n",
    "\n",
    "def load_l3_images_from_predictions(mean_predictions, subjects_w_preds,axials,sagittals):\n",
    "    l3_images = []\n",
    "\n",
    "    for subject in subjects_w_preds:\n",
    "        sagittal_series = [s for s in sagittals if s.subject.id_ == subject.id_][0]\n",
    "        axial_series = [a for a in axials if a.subject.id_ == subject.id_][0]\n",
    "        l3_images.append(\n",
    "            L3Image(\n",
    "                axial_series=axial_series,\n",
    "                sagittal_series=sagittal_series,\n",
    "                prediction_result=MinimalResult(\n",
    "                    MinimalPrediction(\n",
    "                        predicted_y_in_px=mean_predictions[subject.id_]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return l3_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))\n",
    "sagittal_series = load_object(os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runname = 'CV_poorl3'\n",
    "prediction_results_list = sorted([f for f in os.listdir(pickles) if (f.startswith('prediction_results_') and f.endswith(runname+'.pkl'))])\n",
    "folds = len(prediction_results_list)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_predictions = load_l3_predictions(config[\"l3_finder\"][\"output_directory\"],folds)\n",
    "    mean_predictions = calc_mean_predictions(all_predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    subjects_w_preds = find_subjects_w_preds(mean_predictions, list(ingest.find_subjects(config['l3_finder'][\"dicom_dir\"])))\n",
    "    l3_images = load_l3_images_from_predictions(mean_predictions, subjects_w_preds, axial_series, sagittal_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(l3_images,os.path.join(pickles,'l3_images_cv.pkl'))\n",
    "save_object(mean_predictions,os.path.join(pickles,'mean_predictions.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Outlier Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_images = load_object(os.path.join(pickles,'l3_images_cv.pkl'))\n",
    "mean_predictions = load_object(os.path.join(pickles,'mean_predictions.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile  = 'poorl3.csv'\n",
    "df_poorl3 = pd.read_csv(infile, index_col=False)\n",
    "\n",
    "print('Total number of outliers for manual L3 detection: ', len(df_poorl3))\n",
    "l3_absent = df_poorl3.loc[df_poorl3['L3slice'].isnull(),'ID'].values.tolist()\n",
    "print('Cases with L3 not present: ', len(l3_absent))\n",
    "l3_present = df_poorl3.loc[~df_poorl3['L3slice'].isnull(),'ID'].values.tolist()\n",
    "print('Cases with manually identified L3s: ', len(l3_present))\n",
    "\n",
    "l3_outliers = l3_absent + l3_present\n",
    "print(\"Outliers: \", len(l3_outliers))\n",
    "\n",
    "#sagittal_mips_valid = [sagittal_mip for sagittal_mip in sagittal_mips if sagittal_mip.subject_id not in df_poorl3.ID.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of outliers without proper L3 images\n",
    "print('Total l3_images: ', len(l3_images))\n",
    "l3_images = [l3_image for l3_image in l3_images if l3_image.subject_id not in l3_absent]\n",
    "print('Total l3_images after outlier removal: ', len(l3_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_images_out = [l3_image for l3_image in l3_images if l3_image.subject_id in l3_present]\n",
    "print(len(l3_images_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_images_normals = [l3_image for l3_image in l3_images if l3_image.subject_id not in l3_outliers]\n",
    "print(len(l3_images_normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Manual Predictions DICT\n",
    "manualL3s = []\n",
    "for i in range(len(l3_images_out)):\n",
    "    subject_id = l3_images_out[i].subject_id\n",
    "    manualL3s.append(df_poorl3.loc[df_poorl3['ID']==subject_id,'L3slice'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(l3_images_normals,os.path.join(pickles,'l3_images_normals.pkl'))\n",
    "save_object(l3_images_out,os.path.join(pickles,'l3_images_outliers.pkl'))\n",
    "save_object(manualL3s,os.path.join(pickles,'manualL3s.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment L3 Axial Images and Calculate Muscle Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_images_normals = load_object(os.path.join(pickles,'l3_images_normals.pkl'))\n",
    "l3_images_out = load_object(os.path.join(pickles,'l3_images_outliers.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List from epic filter \n",
    "# Changed for V5 to read from csv file\n",
    "df_v5 = pd.read_csv('patlist_with_validBMI_corrected_v5.csv', index_col=False)\n",
    "normal_patients_corrected = list(df_v5.PAT_ID.values)\n",
    "print(len(normal_patients_corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List from Andrew\n",
    "infile  = 'poorl3.csv'\n",
    "df_poorl3 = pd.read_csv(infile, index_col=False)\n",
    "\n",
    "df_l3_present = df_poorl3.loc[~df_poorl3['L3slice'].isnull()]\n",
    "\n",
    "print('Length of df_l3_present: ', len(df_l3_present))\n",
    "\n",
    "df_l3_present_normals = df_l3_present.loc[df_l3_present['ID'].isin(normal_patients_corrected)]\n",
    "\n",
    "print('Length of df_l3_present_normals: ', len(df_l3_present_normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process only the normals selected by epic filter\n",
    "l3_images_normals = [l3 for l3 in l3_images_normals if l3.subject_id in normal_patients_corrected]\n",
    "print('Length of normals processed and in epic filter: ', len(l3_images_normals))\n",
    "\n",
    "l3_images_out = [l3 for l3 in l3_images_out if l3.subject_id in normal_patients_corrected]\n",
    "print('Length of outliers processed and in epic filter: ', len(l3_images_out))\n",
    "\n",
    "manualL3s = [int(df_l3_present_normals.loc[df_l3_present_normals['ID']==l3.subject_id,'L3slice'].values[0]) for l3 in l3_images_out if l3.subject_id]\n",
    "print('Length of manual L3s: ', len(manualL3s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients in Epic filter, but not in normals or outliers [i.e those missing Axial CT itself]\n",
    "\n",
    "all_l3s = l3_images_normals + l3_images_out\n",
    "\n",
    "l3_pats = [l3.subject_id for l3 in all_l3s]\n",
    "\n",
    "missing_CT = [p for p in normal_patients_corrected if p not in l3_pats]\n",
    "\n",
    "print('Patients with L3: ', len(l3_pats))\n",
    "print('Patients from Epic: ',len(normal_patients_corrected))\n",
    "print('Patients Missing Axial CT: ', len(missing_CT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_best_to_manual_l3_and_seg import seg_model_configs\n",
    "from compare_best_to_manual_l3_and_seg import do_segmentation_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"muscle_segmentor\"]['model_path_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    configs = seg_model_configs(config[\"muscle_segmentor\"]['model_path_dir'])\n",
    "    smas,average_masks,tableless_images = do_segmentation_cv(configs, l3_images_normals)\n",
    "    print('Length of smas normals: ',len(smas))\n",
    "    print('Length of average_masks normals: ',len(average_masks))\n",
    "    print('Length of tableless_images normals: ',len(tableless_images))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(manualL3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    configs = seg_model_configs(config[\"muscle_segmentor\"]['model_path_dir'])\n",
    "    smas_out,average_masks_out,tableless_images_out = do_segmentation_cv(configs, l3_images_out, manualL3s)\n",
    "    print('Length of smas outliers: ',len(smas_out))\n",
    "    print('Length of average_masks outliers: ',len(average_masks_out))\n",
    "    print('Length of tableless_images outliers: ',len(tableless_images_out))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smas = smas + smas_out\n",
    "average_masks = average_masks + average_masks_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableless_images = np.concatenate((tableless_images, tableless_images_out),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_images = l3_images_normals + l3_images_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of smas all: ',len(smas))\n",
    "print('Length of average_masks all: ',len(average_masks))\n",
    "print('Length of tableless_images all: ',len(tableless_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imsave\n",
    "import csv\n",
    "\n",
    "def output_sma_results(output_dir, l3_images, tableless_images, average_masks, smas):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    csv_filename = os.path.join(output_dir, \"areas-mm2_by_subject_id.csv\")\n",
    "    with open(csv_filename, \"w\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([\"subject_id\", \"area_mm2\", \"sagittal_series\", \"axial_series\"])\n",
    "        print('Saving Segmentation Results in ', output_dir)\n",
    "        index = 0    \n",
    "        for mask, sma, l3_image, tableless_image in zip(average_masks, smas,l3_images, tableless_images):\n",
    "            index += 1\n",
    "            base = os.path.join(output_dir, str(index) + \"_\" + l3_image.subject_id)\n",
    "            imsave(base + \"_CT.tif\", tableless_image.astype(np.float32))\n",
    "            imsave(base + \"_muscle.tif\", mask * np.iinfo(np.uint8).max)\n",
    "\n",
    "            row = [\n",
    "                l3_image.subject_id,\n",
    "                sma.area_mm2,\n",
    "                l3_image.sagittal_series.series_name,\n",
    "                l3_image.axial_series.series_name,\n",
    "            ]\n",
    "            csv_writer.writerow(row)\n",
    "        print('Total exams outputted: ', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_sma_results(config[\"muscle_segmentor\"]['output_directory'], l3_images, tableless_images, average_masks, smas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
