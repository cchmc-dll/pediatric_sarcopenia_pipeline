{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import get_ipython\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "# Custom modules for debugging\n",
    "from SliceViewer import ImageSliceViewer3D, ImageSliceViewer3D_1view,ImageSliceViewer3D_2views\n",
    "from investigate import *\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", 10)\n",
    "      \n",
    "import json\n",
    "from run_sma_experiment import find_l3_images,output_images\n",
    "import pprint\n",
    "from L3_finder import *\n",
    "\n",
    "# Custom functions\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):        \n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic('tb', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In CCHMC's workflow, there were two dicom dumps, with different folder structures and naming convention:\n",
    "<br>\n",
    "Folder structure: <br>\n",
    "Dump-1: Project_folder/Patient_folder/Series_Folder/dicom_files <br>\n",
    "Dump-2: Project_folder/Patient_folder/Study_folder/Series_Folder/dicom_files<br> \n",
    "<br>\n",
    "Naming Convention for patient folder: <br>\n",
    "Dump-1: PATID-GMRN-PATID-STUDYNAME <br>\n",
    "Dump-2: PT-PATID-PATID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select which dump you are processing here [dump1: 1, dump2: 2]\n",
    "dump = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data = '/tf/data'\n",
    "output = '/tf/pickles/v5_8pts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Load list of normal patients filtered from Epic data and select those patients from the DICOM dump of all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of df_P:  ['GIVEN_MRN', 'PAT_ID', 'ACC']\n",
      "Length of df_P:  2238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIVEN_MRN</th>\n",
       "      <th>PAT_ID</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>807126</td>\n",
       "      <td>Z857672</td>\n",
       "      <td>7443683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11176208</td>\n",
       "      <td>Z1204112</td>\n",
       "      <td>7442667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>834056</td>\n",
       "      <td>Z870530</td>\n",
       "      <td>7219002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1412716</td>\n",
       "      <td>Z1009393</td>\n",
       "      <td>7437949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1051399</td>\n",
       "      <td>Z441477</td>\n",
       "      <td>7449601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11277072</td>\n",
       "      <td>Z1305152</td>\n",
       "      <td>7476367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11021437</td>\n",
       "      <td>Z1049116</td>\n",
       "      <td>7476123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>855379</td>\n",
       "      <td>Z881264</td>\n",
       "      <td>7207613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1004812</td>\n",
       "      <td>Z413629</td>\n",
       "      <td>7206650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>742506</td>\n",
       "      <td>Z828131</td>\n",
       "      <td>7206442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GIVEN_MRN    PAT_ID      ACC\n",
       "0     807126   Z857672  7443683\n",
       "1   11176208  Z1204112  7442667\n",
       "2     834056   Z870530  7219002\n",
       "3    1412716  Z1009393  7437949\n",
       "4    1051399   Z441477  7449601\n",
       "5   11277072  Z1305152  7476367\n",
       "6   11021437  Z1049116  7476123\n",
       "7     855379   Z881264  7207613\n",
       "8    1004812   Z413629  7206650\n",
       "9     742506   Z828131  7206442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load normal patient list\n",
    "infile  = 'patlist_with_validBMI_corrected_v5.csv'\n",
    "df_P = pd.read_csv(infile, index_col=False)\n",
    "df_P = df_P.loc[:, ~df_P.columns.str.contains('^Unnamed')]\n",
    "df_P = df_P[['GIVEN_MRN','PAT_ID','ACC']]\n",
    "print('Columns of df_P: ', list(df_P))\n",
    "print('Length of df_P: ', len(df_P))\n",
    "display(df_P.head(10))\n",
    "#print('# of Unique patients: ', len(df_P.subject_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patient folders in data dir:  8\n"
     ]
    }
   ],
   "source": [
    "pats = next(os.walk(data))[1]\n",
    "print('Total patient folders in data dir: ',len(pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dump == 1:\n",
    "    patids = [pat.split('-')[0] for pat in pats]\n",
    "elif dump == 2:\n",
    "    patids = [pat.split('-')[-1] for pat in pats]\n",
    "\n",
    "valid_ids = [valid_id for valid_id,valid_dir in zip(patids,pats) if valid_id in df_P.PAT_ID.values]\n",
    "\n",
    "valid_ids = set(valid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid ids:  8\n"
     ]
    }
   ],
   "source": [
    "print('valid ids: ',len(valid_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Load each study into subject object\n",
    "<br>\n",
    "Subject object defined in L3finder.ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config dict: \n",
      "{'dicom_dir': '/tf/data',\n",
      " 'model_path': 'None',\n",
      " 'output_directory': '/tf/output',\n",
      " 'overwrite': True,\n",
      " 'save_plots': True,\n",
      " 'series_to_skip_pickle_file': '/tf/output/broken_sagittal_and_axial_series.pkl',\n",
      " 'show_plots': False}\n"
     ]
    }
   ],
   "source": [
    "# Import modules and config file\n",
    "configfile = os.path.join(cwd,'config/debug_ES/series_filter_ds1.json')\n",
    "with open(configfile, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "config = config[\"series_filter\"]        \n",
    "print('Current config dict: ')\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dump==2:\n",
    "    config[\"new_tim_dicom_dir_structure\"] = False\n",
    "elif dump==1:\n",
    "    config[\"new_tim_dicom_dir_structure\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding subjects\n",
      "Subjects found:  8\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(\"Finding subjects\")\n",
    "\n",
    "subjects = list(\n",
    "    find_subjects(\n",
    "        config[\"dicom_dir\"],\n",
    "        new_tim_dir_structure=config[\"new_tim_dicom_dir_structure\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print('Subjects found: ', len(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-3 - check if there are subjects with multiple folders (studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects found:  8\n",
      "Valid Subjects:  8\n"
     ]
    }
   ],
   "source": [
    "subjects = [subject for subject in subjects if subject.id_ in valid_ids]\n",
    "print('Subjects found: ', len(subjects))\n",
    "print('Valid Subjects: ', len(valid_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:  0\n",
      "Uniques:  8\n"
     ]
    }
   ],
   "source": [
    "# Find Duplicate Subjects\n",
    "unique_subjects = []\n",
    "duplicate_subjects = []\n",
    "for subject in subjects:\n",
    "    if subject.id_ not in unique_subjects:\n",
    "        unique_subjects.append(subject.id_)\n",
    "    else:\n",
    "        duplicate_subjects.append(subject.id_)\n",
    "\n",
    "print('Duplicates: ',len(duplicate_subjects)           )\n",
    "print('Uniques: ',len(unique_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save subjects without duplicates\n",
    "save_object(subjects, os.path.join(output,'subjects_noduplicates.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4 - Load each series into series object and keep only axials and sagittals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = load_object(os.path.join(output,'subjects_noduplicates.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding series\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b8119424c2481fa32f8476af20af9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of series found:  45\n",
      "CPU times: user 68.3 ms, sys: 16.6 ms, total: 84.9 ms\n",
      "Wall time: 72.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find series images\n",
    "print(\"Finding series\")\n",
    "series = list(flatten(tqdm((s.find_series() for s in subjects),total=len(subjects))))\n",
    "print(\"Total number of series found: \", len(series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate axial and sagittal series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding series\n",
      "Separating series\n",
      "Filtering series using  48  cores:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3de974c14c45718ecf1c710730aa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Sagittals\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a153e52d27d740bb97f5fdaa75cda4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=45.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Axials\n",
      "Series seperated\n",
      "CPU times: user 220 ms, sys: 720 ms, total: 940 ms\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Debug\n",
    "from L3_finder import *\n",
    "from l3finder.ingest import *\n",
    "from multiprocessing import get_context\n",
    "from multiprocessing import set_start_method\n",
    "#set_start_method(\"spawn\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Find series images\n",
    "    print(\"Finding series\")\n",
    "    series = list(flatten(s.find_series() for s in subjects))\n",
    "\n",
    "    # Separate series\n",
    "    print(\"Separating series\")\n",
    "    #sagittal_series, axial_series, excluded_series = separate_series(series)\n",
    "    \n",
    "    excluded_series = []\n",
    "\n",
    "    sag_filter = functools.partial(\n",
    "        same_orientation,\n",
    "        orientation='sagittal',\n",
    "        excluded_series=excluded_series\n",
    "    )\n",
    "    \n",
    "    axial_filter = functools.partial(\n",
    "        same_orientation,\n",
    "        orientation='axial',\n",
    "        excluded_series=excluded_series\n",
    "    )\n",
    "\n",
    "    def pool_filter(pool, func, candidates):\n",
    "        return [\n",
    "            c for c, keep\n",
    "            in zip(candidates, tqdm(pool.imap(func, candidates),total=len(candidates)))\n",
    "            if keep]\n",
    "    \n",
    "    print('Filtering series using ', multiprocessing.cpu_count(), ' cores:')\n",
    "    with get_context(\"spawn\").Pool() as p:\n",
    "        sagittal_series = pool_filter(p, sag_filter, series)\n",
    "        print(\"Processed Sagittals\")\n",
    "        axial_series = pool_filter(p, axial_filter, series)\n",
    "        print(\"Processed Axials\")\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Series seperated\")\n",
    "\n",
    "#remove_start_method(\"spawn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of valid pats:  8\n",
      "Length of sagittal series 1\n",
      "Length of axial series 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of valid pats: \", len(subjects))\n",
    "print(\"Length of sagittal series\", len(sagittal_series))\n",
    "print(\"Length of axial series\", len(axial_series))\n",
    "#print(\"Length of excluded series\", len(excluded_series))\n",
    "#print(\"Length of all series in dataset\", len(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save required objects\n",
    "save_object(axial_series, os.path.join(output,'axial_series.pkl'))\n",
    "save_object(sagittal_series, os.path.join(output,'sagittal_series.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Investigate subjects and series using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(output,'axial_series.pkl'))\n",
    "sagittal_series = load_object(os.path.join(output,'sagittal_series.pkl'))\n",
    "subjects = load_object(os.path.join(output,'subjects_noduplicates.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = get_summary_dfs(axial_series,sagittal_series,subjects)\n",
    "save_object(df_a, os.path.join(output,'df_a.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Axials</th>\n",
       "      <th>Sagittals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z923887</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z1107859</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z1312350</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z934614</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Z1146560</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Z719159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Z1141194</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Z1199636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Axials Sagittals\n",
       "0   Z923887      2         0\n",
       "1  Z1107859      2         0\n",
       "2  Z1312350      2         0\n",
       "3   Z934614      3         0\n",
       "4  Z1146560      2         0\n",
       "5   Z719159      2         0\n",
       "6  Z1141194      2         1\n",
       "7  Z1199636      1         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_a.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_a_axials = get_summary_by_serieslength(axial_series)\n",
    "df_a_sags = get_summary_by_serieslength(sagittal_series)\n",
    "save_object(df_a_axials, os.path.join(output,'df_a_axials.pkl'))\n",
    "save_object(df_a_sags, os.path.join(output,'df_a_sags.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of subjects with atleast 1 axial or sagittal series:  8\n",
      "Length of subjects with atleast 1 axial series:  8\n",
      "Length of subjects with atleast 1 sagittal series:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of subjects with atleast 1 axial or sagittal series: \", len(df_a))\n",
    "print(\"Length of subjects with atleast 1 axial series: \", len(df_a_axials['ID'].unique()))\n",
    "print(\"Length of subjects with atleast 1 sagittal series: \", len(df_a_sags['ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Patients without Axial\n",
    "pats = [pat for pat in df_a['ID'].values if pat not in df_a_axials['ID'].values]\n",
    "print(len(pats))\n",
    "print(pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Patients without Sagittal\n",
    "pats = [pat for pat in df_a['ID'].values if pat not in df_a_sags['ID'].values]\n",
    "print(len(pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imseries = get_subject_series('Z837620','Z837620-SE-6-Vol_Body_Vol._0.5',subjects)\n",
    "print(imseries.orientation,' ' , imseries.slice_thickness)\n",
    "imdata = imseries.pixel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(imdata.shape)\n",
    "ImageSliceViewer3D(imdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary_by_serieslength(df_a_axials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary_by_serieslength(df_a_sags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6 - Create dataframe of optimal axial sagittal pairs\n",
    "\n",
    "The function filter_finalpairs in investigate.py is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(output,'axial_series.pkl'))\n",
    "sagittal_series = load_object(os.path.join(output,'sagittal_series.pkl'))\n",
    "subjects = load_object(os.path.join(output,'subjects_noduplicates.pkl'))\n",
    "\n",
    "df_a_axials = load_object(os.path.join(output,'df_a_axials.pkl'))\n",
    "df_a_sags = load_object(os.path.join(output,'df_a_sags.pkl'))\n",
    "df_a = load_object(os.path.join(output,'df_a.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding IDs\n",
      "Filtering series using  48  cores:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c708a3263aac49ca9322a83199167be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parallel processing over\n",
      "Processed\n",
      "CPU times: user 211 ms, sys: 87.7 ms, total: 299 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from L3_finder import *\n",
    "from l3finder.ingest import *\n",
    "from multiprocessing import get_context\n",
    "from multiprocessing import set_start_method\n",
    "#set_start_method(\"spawn\")\n",
    "df_filt = None\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Find series images\n",
    "    print(\"Finding IDs\")\n",
    "    \n",
    "    IDs = [s.id_ for s in subjects]\n",
    "    pair_filter = functools.partial(\n",
    "        filter_finalpairs,\n",
    "        df_ax=df_a_axials,\n",
    "        df_sag=df_a_sags,\n",
    "        subjects=subjects\n",
    "    )\n",
    "    \n",
    "    def pool_filter(pool, func, candidates):\n",
    "        return [a for a in tqdm(pool.imap(func, candidates),total=len(candidates))]\n",
    "        \n",
    "    print('Filtering series using ', multiprocessing.cpu_count(), ' cores:')\n",
    "        \n",
    "    with get_context(\"spawn\").Pool(4) as p:\n",
    "        result_list = pool_filter(p, pair_filter, IDs)\n",
    "        p.close()\n",
    "        p.join()\n",
    "    \n",
    "    print('parallel processing over')\n",
    "     # Start from here\n",
    "    df_filt  = pd.DataFrame(columns=['ID','Axial','Sagittal','Overlap','MissingScore','PairValidity', \n",
    "                                'AxSlices','SagSlices','AxThick','SagThick'])\n",
    "    for i,op in enumerate(result_list):\n",
    "        df_filt.loc[i] = op\n",
    "    \n",
    "\n",
    "print(\"Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(df_filt, os.path.join(output,'df_filteredpairs.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Investigate the dataframe for missing and low quality pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all params\n",
    "df_filt = load_object(os.path.join(output,'df_filteredpairs.pkl'))\n",
    "axial_series = load_object(os.path.join(output,'axial_series.pkl'))\n",
    "sagittal_series = load_object(os.path.join(output,'sagittal_series.pkl'))\n",
    "subjects = load_object(os.path.join(output,'subjects_noduplicates.pkl'))\n",
    "\n",
    "df_a_axials = load_object(os.path.join(output,'df_a_axials.pkl'))\n",
    "df_a_sags = load_object(os.path.join(output,'df_a_sags.pkl'))\n",
    "df_a = load_object(os.path.join(output,'df_a.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered df:  8\n",
      "Length of subjects:  8\n"
     ]
    }
   ],
   "source": [
    "# Make sure filtered df and subjects are equal length\n",
    "print('Length of filtered df: ',len(df_filt))\n",
    "print('Length of subjects: ',len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects without Axials:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Axial</th>\n",
       "      <th>Sagittal</th>\n",
       "      <th>Overlap</th>\n",
       "      <th>MissingScore</th>\n",
       "      <th>PairValidity</th>\n",
       "      <th>AxSlices</th>\n",
       "      <th>SagSlices</th>\n",
       "      <th>AxThick</th>\n",
       "      <th>SagThick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Axial, Sagittal, Overlap, MissingScore, PairValidity, AxSlices, SagSlices, AxThick, SagThick]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View and Remove subjects without axial series\n",
    "df_noaxials =  df_filt[df_filt['Axial'].isnull()]\n",
    "print('Number of subjects without Axials: ', len(df_noaxials))\n",
    "display(df_noaxials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of subjects with axials:  8\n"
     ]
    }
   ],
   "source": [
    "# Remove subjects without axials from subjects list:\n",
    "subjects = [s for s in subjects if s.id_ not in df_noaxials.ID.values]\n",
    "print('Length of subjects with axials: ',len(subjects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases without sagittals:  7\n"
     ]
    }
   ],
   "source": [
    "# Print cases that don't have sagittals\n",
    "df_nosags = df_filt[df_filt['Sagittal'].isnull()]\n",
    "print(\"Number of cases without sagittals: \", len(df_nosags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases with overlap < 0.7:  0\n"
     ]
    }
   ],
   "source": [
    "# Investigate cases with less than 0.7 overlap and  < 0.9 Missing Score [Tracks Slices missing from stack]\n",
    "df_pooroverlap = df_filt[(df_filt['Overlap'] < 0.7) | (df_filt['MissingScore'] < 0.9)]\n",
    "print('Cases with overlap < 0.7: ', len(df_pooroverlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Axial</th>\n",
       "      <th>Sagittal</th>\n",
       "      <th>Overlap</th>\n",
       "      <th>MissingScore</th>\n",
       "      <th>PairValidity</th>\n",
       "      <th>AxSlices</th>\n",
       "      <th>SagSlices</th>\n",
       "      <th>AxThick</th>\n",
       "      <th>SagThick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Axial, Sagittal, Overlap, MissingScore, PairValidity, AxSlices, SagSlices, AxThick, SagThick]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_pooroverlap.sort_values(by=['MissingScore'],ascending=[True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy Functions to investigate the poor pairs\n",
    "def get_ax_sag(df,ind):\n",
    "    global subjects\n",
    "    subid = df.loc[ind,'ID']\n",
    "    axid = df.loc[ind,'Axial']\n",
    "    sagid = df.loc[ind,'Sagittal']\n",
    "    ax = get_subject_series(subid,axid,subjects)\n",
    "    sag = get_subject_series(subid,sagid,subjects)\n",
    "    return ax,sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_missing_slices_sagittals(get_ax_sag(df_pooroverlap,85)[1]),verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_series_overlap(*get_ax_sag(df_pooroverlap,85),verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on investigation, eliminate series and subjects not eligible and create final df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Sagittals only when overlap > 0.7\n",
    "df_final = df_filt.copy()\n",
    "for ind,row in df_final.iterrows():\n",
    "    if (not row['Overlap']) or (row['Overlap'] < 0.7):\n",
    "            df_final.loc[ind,'Sagittal'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases without sagittals in filter df:  7\n",
      "Number of cases without sagittals in final df:  7\n"
     ]
    }
   ],
   "source": [
    "# Print cases that don't have sagittals\n",
    "print(\"Number of cases without sagittals in filter df: \", len(df_nosags))\n",
    "df_nosags2 = df_final[df_final['Sagittal'].isnull()]\n",
    "print(\"Number of cases without sagittals in final df: \", len(df_nosags2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final \n",
    "\n",
    "final_df_file = 'df_final_dump_'+str(dump)+'_8pats.pkl'\n",
    "final_subs_file = 'subjects_final_dump_'+str(dump)+'_8pats.pkl'\n",
    "\n",
    "save_object(df_final, os.path.join(output,final_df_file))\n",
    "save_object(subjects, os.path.join(output,final_subs_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
