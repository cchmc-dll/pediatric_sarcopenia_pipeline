{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load libraries and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-y6bntoam because the default path (/home/jupyteruser/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80a028ebf4c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Custom modules for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSliceViewer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageSliceViewer3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageSliceViewer3D_1view\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mImageSliceViewer3D_2views\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minvestigate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/smipipeline/SliceViewer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipyw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_testdata_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilereader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_dicomdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "source": [
    "# from IPython import get_ipython\n",
    "#from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "# Custom modules for debugging\n",
    "from SliceViewer import ImageSliceViewer3D, ImageSliceViewer3D_1view,ImageSliceViewer3D_2views\n",
    "from investigate import *\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", 10)\n",
    "      \n",
    "import json\n",
    "from run_sma_experiment import find_l3_images,output_images\n",
    "import pprint\n",
    "from L3_finder import *\n",
    "\n",
    "# Custom functions\n",
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):        \n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('tb', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "data = '/tf/data'\n",
    "pickles = '/tf/pickles'\n",
    "models = '/tf/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules and config file\n",
    "configfile = os.path.join(cwd,'config/debug_ES/run_prediction_CV_poorl3.json')\n",
    "with open(configfile, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Process final images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Load each study into subject object\n",
    "<br>\n",
    "Subject object defined in L3finder.ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['l3_finder']['new_tim_dicom_dir_structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "print(\"Finding subjects\")\n",
    "\n",
    "subjects = list(\n",
    "    find_subjects(\n",
    "        config['l3_finder'][\"dicom_dir\"],\n",
    "        new_tim_dir_structure=config['l3_finder']['new_tim_dicom_dir_structure']\n",
    "    )\n",
    ")\n",
    "\n",
    "print('Subjects found: ', len(subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section-3 - check if there are subjects with multiple folders (studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find series images\n",
    "print(\"Finding series\")\n",
    "series = list(flatten(tqdm((s.find_series() for s in subjects),total=len(subjects))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of series found: \", len(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sagittal_series, axial_series, excluded_series = separate_series(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of valid pats: \", len(subjects))\n",
    "print(\"Length of sagittal series\", len(sagittal_series))\n",
    "print(\"Length of axial series\", len(axial_series))\n",
    "print(\"Length of excluded series\", len(excluded_series))\n",
    "print(\"Length of all series in dataset\", len(series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure each subject has at the max only 1 axial and 1 sagittal series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_ids = [ax.subject.id_ for ax in axial_series]\n",
    "sag_ids = [sag.subject.id_ for sag in sagittal_series]\n",
    "\n",
    "def find_duplicates(id_list):\n",
    "    uniques = []\n",
    "    duplicates = []\n",
    "    for ids in id_list:\n",
    "        if ids in uniques:\n",
    "            duplicates.append(ids)\n",
    "        else:\n",
    "            uniques.append(ids)\n",
    "            \n",
    "    return uniques,duplicates\n",
    "\n",
    "\n",
    "ax_u,ax_d = find_duplicates(ax_ids)\n",
    "sag_u,sag_d = find_duplicates(sag_ids)\n",
    "\n",
    "print('Ax duplicates: ', ax_d)\n",
    "print('Sag duplicates: ', sag_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the series objects to investigate\n",
    "ax_d_series = [ax for ax in axial_series if ax.subject.id_ in ax_d]\n",
    "sag_d_series = [ax for ax in sagittal_series if ax.subject.id_ in ax_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dl= load_object(os.path.join(pickles,'df_final.pkl'))\n",
    "display(df_dl[df_dl['ID']==ax_d[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Missing Sagittals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default code filters 0.5mm slices, but I am letting them pass by setting it to 0\n",
    "constructed_sagittals = construct_series_for_subjects_without_sagittals(\n",
    "        subjects, sagittal_series, axial_series,thickness_filter=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "        \"Series separated\\n\",\n",
    "        len(sagittal_series), \"sagittal series.\",\n",
    "        len(axial_series), \"axial series.\",\n",
    "        len(excluded_series), \"excluded series.\",\n",
    "        len(constructed_sagittals), \"constructed series.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagittal_series.extend(constructed_sagittals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(axial_series,os.path.join(pickles,'axial_curated.pkl'))\n",
    "save_object(sagittal_series,os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating sagittal MIPS\")\n",
    "mips = create_sagittal_mips_from_series(\n",
    "        many_series=sagittal_series,\n",
    "        cache_dir=config['l3_finder'].get(\"cache_dir\", None),\n",
    "        cache=config['l3_finder'].get(\"cache_intermediate_results\", False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(mips,os.path.join(pickles,'mips.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mips = load_object(os.path.join(pickles,'mips.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing Images\")\n",
    "preprocessed_images = preprocess_images(mips)\n",
    "\n",
    "# Sagittal mip is redundant, get rid just use preprocessed images\n",
    "sagittal_mips = [SagittalMIP(i) for i in preprocessed_images]\n",
    "\n",
    "print(\"Separate heights for better batching\")\n",
    "mips_by_dimension = group_mips_by_dimension(sagittal_mips)\n",
    "print(\"Dimensions in set:\", mips_by_dimension.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(mips_by_dimension,os.path.join(pickles,'mips_by_dimension.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find L3 - step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mips_by_dimension = load_object(os.path.join(pickles,'mips_by_dimension.pkl'))\n",
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))\n",
    "sagittal_series = load_object(os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all models in model path dir\n",
    "models_dir = config['l3_finder']['model_path_dir']\n",
    "\n",
    "# Get all models in models dir\n",
    "models_list = sorted([f for f in os.listdir(models_dir) if f.endswith('.h5')])\n",
    "print(models_list)\n",
    "folds = len(models_list)\n",
    "\n",
    "for fold in range(folds):\n",
    "    model_path = os.path.join(models_dir,models_list[fold])\n",
    "    print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load age information from patlist csv\n",
    "# Load normal patient list\n",
    "infile  = 'poorl3.csv'\n",
    "df_poorl3 = pd.read_csv(infile, index_col=False)\n",
    "display(df_poorl3.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of outliers for manual L3 detection: ', len(df_poorl3))\n",
    "l3_absent = df_poorl3.loc[df_poorl3['L3slice'].isnull(),'ID'].values.tolist()\n",
    "print('Cases with L3 not present: ', len(l3_absent))\n",
    "l3_present = df_poorl3.loc[~df_poorl3['L3slice'].isnull(),'ID'].values.tolist()\n",
    "print('Cases with manually identified L3s: ', len(l3_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dimension, sagittal_mips in mips_by_dimension.items():\n",
    "    print('Dimension: ', dimension)\n",
    "    print(len(sagittal_mips))\n",
    "    sagittal_mips_valid = [sagittal_mip for sagittal_mip in sagittal_mips if sagittal_mip.subject_id not in df_poorl3.ID.values]\n",
    "    print(len(sagittal_mips_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runname = 'CV_poorl3'\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(folds):\n",
    "        model_path = os.path.join(models_dir,models_list[fold])\n",
    "        print(\"Making predictions for fold \", fold, 'Path: ', model_path)\n",
    "        prediction_results = []\n",
    "        prediction_errors = []\n",
    "        for dimension, sagittal_mips in mips_by_dimension.items():\n",
    "            sagittal_mips_valid = [sagittal_mip for sagittal_mip in sagittal_mips if sagittal_mip.subject_id not in df_poorl3.ID.values]\n",
    "            dim_group_results,errors = make_predictions_for_sagittal_mips(\n",
    "                sagittal_mips_valid,\n",
    "                model_path=model_path,\n",
    "                shape=dimension\n",
    "            )\n",
    "            prediction_results.extend(dim_group_results)\n",
    "            prediction_errors.extend(errors)\n",
    "\n",
    "        # Save prediction results\n",
    "        pred_results_file = 'prediction_results_' + str(fold) + '_' +  runname + '.pkl'\n",
    "        pred_errors_file = 'prediction_errors_' + str(fold) + '_' +  runname + '.pkl'\n",
    "        save_object(prediction_results,os.path.join(pickles,pred_results_file))\n",
    "        save_object(prediction_errors,os.path.join(pickles,pred_errors_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save l3 prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(axial_series[0].subject.id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series_valid = [axial for axial in axial_series if axial.subject.id_ not in df_poorl3.ID.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prediction_results pickle files\n",
    "runname = 'CV_poorl3'\n",
    "\n",
    "output_dir = config[\"l3_finder\"][\"output_directory\"]\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "prediction_results_list = sorted([f for f in os.listdir(pickles) if (f.startswith('prediction_results_') and f.endswith(runname+'.pkl'))])\n",
    "folds = len(prediction_results_list)\n",
    "print(folds)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for fold in range(folds):\n",
    "        pred_file = os.path.join(pickles,prediction_results_list[fold])\n",
    "        prediction_results = load_object(pred_file)\n",
    "        print('Total predictions: ',len(prediction_results))\n",
    "        print('Building L3 images for fold: ', fold)\n",
    "        l3_images = build_l3_images(axial_series_valid, prediction_results)\n",
    "        print('Total images: ',len(l3_images))\n",
    "        # Don't run this unless you have new L3 results\n",
    "        print(\"Outputting L3 images for fold: \", fold)\n",
    "        # Clears pixel data from memory aafter outputting\n",
    "        output_dir = os.path.join(config[\"l3_finder\"][\"output_directory\"],str(fold))\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        l3_images = output_images(\n",
    "        l3_images,\n",
    "        args=dict(\n",
    "            output_directory=output_dir,\n",
    "            should_plot=config[\"l3_finder\"][\"show_plots\"],\n",
    "            should_overwrite=config[\"l3_finder\"][\"overwrite\"],\n",
    "            should_save_plots=config[\"l3_finder\"][\"save_plots\"]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mean L3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from L3_finder import L3Image\n",
    "from l3finder import ingest\n",
    "\n",
    "from compare_best_to_manual_l3_and_seg import MinimalPrediction, MinimalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_l3_predictions(l3_prediction_dir,nfolds):\n",
    "    subject_id_col = 0\n",
    "    pred_in_px_col = 1\n",
    "    predictions = defaultdict(list)\n",
    "\n",
    "    for fold_index in range(0, nfolds):\n",
    "        csv_dir = os.path.join(l3_prediction_dir,str(fold_index))\n",
    "        csv_path = Path(csv_dir,'l3_prediction_results.csv')\n",
    "        with open(csv_path) as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            next(reader)\n",
    "\n",
    "            for row in reader:\n",
    "                subid = row[subject_id_col].split('-')[0]\n",
    "                predictions[subid].append(float(row[pred_in_px_col]))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def calc_mean_predictions(all_predictions: defaultdict):\n",
    "    result = {}\n",
    "    for subject_id, prediction_list in all_predictions.items():\n",
    "        result[subject_id] = np.mean(prediction_list)\n",
    "    return result\n",
    "\n",
    "def find_subjects_w_preds(predictions, all_subjects):\n",
    "    subject_ids_w_preds = set(predictions.keys())\n",
    "    return [s for s in all_subjects if s.id_ in subject_ids_w_preds]\n",
    "\n",
    "def load_l3_images_from_predictions(mean_predictions, subjects_w_preds,axials,sagittals):\n",
    "    l3_images = []\n",
    "\n",
    "    for subject in subjects_w_preds:\n",
    "        sagittal_series = [s for s in sagittals if s.subject.id_ == subject.id_][0]\n",
    "        axial_series = [a for a in axials if a.subject.id_ == subject.id_][0]\n",
    "        l3_images.append(\n",
    "            L3Image(\n",
    "                axial_series=axial_series,\n",
    "                sagittal_series=sagittal_series,\n",
    "                prediction_result=MinimalResult(\n",
    "                    MinimalPrediction(\n",
    "                        predicted_y_in_px=mean_predictions[subject.id_]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return l3_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_series = load_object(os.path.join(pickles,'axial_curated.pkl'))\n",
    "sagittal_series = load_object(os.path.join(pickles,'sagittal_curated.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runname = 'CV_poorl3'\n",
    "prediction_results_list = sorted([f for f in os.listdir(pickles) if (f.startswith('prediction_results_') and f.endswith(runname+'.pkl'))])\n",
    "folds = len(prediction_results_list)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_predictions = load_l3_predictions(config[\"l3_finder\"][\"output_directory\"],folds)\n",
    "    mean_predictions = calc_mean_predictions(all_predictions)\n",
    "    subjects_w_preds = find_subjects_w_preds(mean_predictions, list(ingest.find_subjects(config['l3_finder'][\"dicom_dir\"])))\n",
    "    l3_images = load_l3_images_from_predictions(mean_predictions, subjects_w_preds, axial_series, sagittal_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l3_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_best_to_manual_l3_and_seg import seg_model_configs\n",
    "from compare_best_to_manual_l3_and_seg import do_segmentation_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    configs = seg_model_configs(config[\"muscle_segmentor\"]['model_path_dir'])\n",
    "    smas,average_masks,tableless_images = do_segmentation_cv(configs, l3_images)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imsave\n",
    "\n",
    "def output_sma_results(output_dir, l3_images, tableless_images, average_masks, smas):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    csv_filename = os.path.join(output_dir, \"areas-mm2_by_subject_id.csv\")\n",
    "    with open(csv_filename, \"w\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([\"subject_id\", \"area_mm2\", \"sagittal_series\", \"axial_series\"])\n",
    "        print('Saving Segmentation Results in ', output_dir)\n",
    "        index = 0    \n",
    "        for mask, sma, l3_image, tableless_image in zip(average_masks, smas,l3_images, tableless_images):\n",
    "            index += 1\n",
    "            base = os.path.join(output_dir, str(index) + \"_\" + l3_image.subject_id)\n",
    "            imsave(base + \"_CT.tif\", tableless_image.astype(np.float32))\n",
    "            imsave(base + \"_muscle.tif\", mask * np.iinfo(np.uint8).max)\n",
    "\n",
    "            row = [\n",
    "                l3_image.subject_id,\n",
    "                sma.area_mm2,\n",
    "                l3_image.sagittal_series.series_name,\n",
    "                l3_image.axial_series.series_name,\n",
    "            ]\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_sma_results(config[\"muscle_segmentor\"]['output_directory'], l3_images, tableless_images, average_masks, smas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
