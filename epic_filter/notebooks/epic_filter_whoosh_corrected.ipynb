{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.query import *\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta as dt\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "#os.chdir('C:\\\\Users\\\\somd7w\\\\Desktop\\\\DL_Projects\\\\preproc_cntr')\n",
    "cwd = os.getcwd()\n",
    "data =cwd+'/data'\n",
    "output=cwd+'/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def read_sheet(a):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_dict[str(a)], index_col=False)\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_dict[str(a)],index_col=False,encoding='latin-1')\n",
    "        except:\n",
    "            print('Error Opening CSV File')\n",
    "    print(\"Columns of sheet: \",a)\n",
    "    print(list(df))\n",
    "    return df\n",
    "\n",
    "def get_df_stats(df,drop_cols):\n",
    "    # Drop rows if values are NaN in PAT_ID, CT_SCAN_DATE\n",
    "    df = df.dropna(subset=drop_cols)\n",
    "    # Unique PAT_IDs and Given_MRN:\n",
    "    print(\"Number of rows in sheet = \",len(df))\n",
    "    pat_ids = df.PAT_ID.unique()\n",
    "    print(\"Number of unique PAT_IDs = \",len(pat_ids))\n",
    "    mrns = df.GIVEN_MRN.unique()\n",
    "    print(\"Number of unique MRNs = \",len(mrns))\n",
    "   # accs = df.ACC.unique()\n",
    "   # print(\"Number of unique ACC = \",len(accs))\n",
    "    return(df)\n",
    "    \n",
    "def filter_duplicates(df,filter_col,sort_order):\n",
    "    if sort_order == 'ascending':\n",
    "     #   print('Sorting by ascending order and returning largest value')\n",
    "        df = df.sort_values(by=[filter_col])\n",
    "    else:\n",
    "      #  print('Sorting by descending order and returning smallest value')\n",
    "        df = df.sort_values(by=[filter_col],ascending=False)\n",
    "    \n",
    "    df = df.drop_duplicates('PAT_ID', keep='last')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Read CSV files from EPIC query, print and store as Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "csv_list = find_csv_filenames(data)\n",
    "csv_dict = {}\n",
    "print(\"List of Files from EPIC Query:\")\n",
    "for i,csv in enumerate(csv_list):\n",
    "    print(i+1,': ',csv)\n",
    "    csv_dict[str(i+1)] = os.path.join(data,csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(csv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 1: Read Sheet 2 - Imaging Result\n",
    "\n",
    "| Field        \t| Field description                  \t|\n",
    "|--------------\t|------------------------------------\t|\n",
    "| GIVEN_MRN    \t| MRN provided                       \t|\n",
    "| NEW_MRN      \t| New MRN (if updated)               \t|\n",
    "| PAT_ID       \t| Patient Identifier field           \t|\n",
    "| CT_SCAN_DATE \t| Scan completed date provided       \t|\n",
    "| ACC          \t| Accession number provided          \t|\n",
    "| STUDYRESULT  \t| Result narrrative text             \t|\n",
    "| IMPRESSION   \t| Impression notes related to result \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df_2 = read_sheet(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows if values are NaN in PAT_ID, CT_SCAN_DATE\n",
    "drop_cols =['PAT_ID','CT_SCAN_DATE']\n",
    "df_2 = get_df_stats(df_2,drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df_2['CT_SCAN_DATE'] = pd.to_datetime(df_2.CT_SCAN_DATE)\n",
    "df_2['CT_SCAN_DATE'] = df_2['CT_SCAN_DATE'].dt.date\n",
    "df_F = df_2\n",
    "del(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize Sheet\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('earliest date: ',min(df_F['CT_SCAN_DATE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('earliest date: ',max(df_F['CT_SCAN_DATE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 2: Read Sheet 1 - Height, Weight, BMI sheet \n",
    "\n",
    "| Field                  \t| Field description        \t|\n",
    "|------------------------\t|--------------------------\t|\n",
    "| GIVEN_MRN              \t| MRN provided             \t|\n",
    "| NEW_MRN                \t| New MRN (if updated)     \t|\n",
    "| PAT_ID                 \t| Patient Identifier field \t|\n",
    "| ACC                    \t| Given Accession number   \t|\n",
    "| CT_SCAN_DATE           \t| Given completed date     \t|\n",
    "| WEIGHT                 \t| Weight (in kg)           \t|\n",
    "| HEIGHT                 \t| Height (in cm)           \t|\n",
    "| BMI_FOR_AGE_PERCENTILE \t| BMI for age percentile   \t|\n",
    "| BMI_CALCULATED         \t| Calculated BMI           \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = read_sheet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows if values are NaN in PAT_ID, CT_SCAN_DATE\n",
    "drop_cols =['PAT_ID','CT_SCAN_DATE']\n",
    "df_1 = get_df_stats(df_1,drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_1))\n",
    "df_1 = filter_duplicates(df_1,'CT_SCAN_DATE','ascending')\n",
    "print(len(df_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize Sheet\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "print(\"Merge Imaging and BMI Results on PAT_ID and CT_SCAN_DATE and keeping the latest record for duplicates\")\n",
    "df_1['CT_SCAN_DATE'] = pd.to_datetime(df_1.CT_SCAN_DATE)\n",
    "df_1['CT_SCAN_DATE'] = df_1['CT_SCAN_DATE'].dt.date\n",
    "df_F = df_F.merge(df_1.drop(['GIVEN_MRN','NEW_MRN','ACC'],axis=1),how='inner', on=['PAT_ID','CT_SCAN_DATE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = filter_duplicates(df_F,'CT_SCAN_DATE','ascending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_F = get_df_stats(df_F,drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize Sheet\n",
    "display(df_F.head(100))\n",
    "df_F.to_csv(output+'/corrected_whoosh_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 3: Read Sheet 7 - Patient Problem List\n",
    "\n",
    "| Field          \t| Field description                         \t|\n",
    "|----------------\t|-------------------------------------------\t|\n",
    "| GIVEN_MRN      \t| MRN provided                              \t|\n",
    "| NEW_MRN        \t| New MRN (if updated)                      \t|\n",
    "| PAT_ID         \t| Patient Identifier field                  \t|\n",
    "| PROBLEM        \t| Diagnosis/problem description             \t|\n",
    "| NOTED_DATE     \t| Date of diagnosis                         \t|\n",
    "| CODE           \t| ICD code associated                       \t|\n",
    "| PROBLEM_STATUS \t| Status of problem active/resolved/deleted \t|\n",
    "| DATE_OF_ENTRY  \t| Date of record entry                      \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_7 = read_sheet(7)\n",
    "#Visualize Sheet\n",
    "df_7 = get_df_stats(df_7,['PAT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Sort by Latest date for problem list\n",
    "df_7['DATE_OF_ENTRY'] = pd.to_datetime(df_7.DATE_OF_ENTRY)\n",
    "df_7 = df_7.sort_values(by='DATE_OF_ENTRY',ascending=False)\n",
    "display(df_7.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "display(df_7[df_7['PAT_ID'].isin(['Z1256768','Z832424'])])\n",
    "df_debug = df_7[df_7['PAT_ID'].isin(['Z1256768','Z832424'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from data.search_terms_v5 import get_terms\n",
    "problem_list = get_terms()\n",
    "# Convert all terms to lower for Whoosh search\n",
    "problem_list = {k.lower(): [vi.lower() for vi in v] for k, v in problem_list.items()}\n",
    "display(problem_list)\n",
    "#print(len(problem_list.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "print(len(problem_list.keys()))\n",
    "n_searchterms = list(itertools.chain(*problem_list.values()))\n",
    "print('Number of problems: ', len(n_searchterms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find number of patients that are in the problem list\n",
    "print(\"Number of patients in Master List: \")\n",
    "print(len(df_F))\n",
    "print(\"Number of patients in Problem List: \")\n",
    "prob_pats = [pat_id for pat_id in df_F.PAT_ID if pat_id in df_7.PAT_ID.values]\n",
    "print(len(prob_pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df_F[\"PROBLEM_GROUP\"] = None\n",
    "df_F[\"PROBLEM_ID\"] = None\n",
    "df_F[\"PROBLEMS\"] = None\n",
    "pat_ind = df_F.PAT_ID.isin(prob_pats).values\n",
    "pat_ind_neg =~pat_ind\n",
    "df_F.loc[pat_ind_neg, 'PROBLEM_GROUP'] = 'no_problem'\n",
    "df_F.loc[pat_ind, 'PROBLEM_GROUP'] = 'unknown_problem'\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for Problem List search\n",
    "schema = Schema(mrn=ID(stored=True), content=TEXT(stored=True))\n",
    "\n",
    "# indexdir is a directory to store the search index\n",
    "ix = create_in(output+'/whoosh', schema)\n",
    "\n",
    "writer = ix.writer()\n",
    "\n",
    "for ind in df_7.index:\n",
    "    # add a document to search index that is keyed by MRN with the content being the problem list\n",
    "    #print (ind)\n",
    "    problem = df_7.loc[ind,'PROBLEM']\n",
    "    pat_id = df_7.loc[ind,'PAT_ID']\n",
    "    #print(problem)\n",
    "    #break\n",
    "    if pd.isnull(problem):\n",
    "        #print(problem,type(problem))\n",
    "        problem = ''\n",
    "    writer.add_document(\n",
    "    mrn=pat_id,\n",
    "    content=problem\n",
    "    )\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Query\n",
    "with ix.searcher() as searcher:\n",
    "    # get all of the terms from the problem list and make term objects\n",
    "    #terms = [Term(\"content\", problem) for problem in itertools.chain.from_iterable(problem_list.values())]\n",
    "    for key,value in problem_list.items():\n",
    "        terms = list()\n",
    "        for problem in value:\n",
    "            if isinstance(problem, str):\n",
    "                words = problem.split(' ')\n",
    "                if len(words) == 1:\n",
    "                   # print(problem)\n",
    "                    terms.append(Term(\"content\",problem))\n",
    "                else:\n",
    "                    word_t  = list()\n",
    "                    for word in words:\n",
    "                        word_t.append(Term(\"content\",word))\n",
    "                    terms.append(And(word_t))\n",
    "            else:\n",
    "                phrase = list()\n",
    "                for prob in problem:\n",
    "                    phrase.append(Term(\"content\",prob))\n",
    "                #print(phrase)    \n",
    "                terms.append(And(phrase))\n",
    "  \n",
    "        # Generates a query that will match cancer or lymphoma or neuroblastoma or ... and so on\n",
    "        query = Or(terms)\n",
    "\n",
    "        # terms=True so we can see what matched, limit=None b/c we want all matches\n",
    "        results = searcher.search(query, terms=True, limit=None)\n",
    "        print(results.estimated_length())\n",
    "        print(\"Group searched\", key)\n",
    "        for hit in results:\n",
    "          #  print(hit['mrn'])\n",
    "          #  print([x[1] for x in hit.matched_terms()])\n",
    "            if hit['mrn'] in prob_pats:\n",
    "               # print (hit['mrn'], ' ',df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'].values)\n",
    "                if df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'].values[0] == 'unknown_problem':\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'] = key\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()]))\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEMS']  = hit['content']\n",
    "                else:\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'] = key + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'].values[0]\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()])) + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_ID'].values[0]\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEMS']  = hit['content'] + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEMS'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "display(df_F[df_F['PAT_ID'].isin(['Z1256768','Z832424'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.to_csv(output+'/corrected_whoosh_data_withProblemList.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Read Sheet 6 - Medication List\n",
    "\n",
    "| Field         \t| Field description             \t|\n",
    "|---------------\t|-------------------------------\t|\n",
    "| GIVEN_MRN     \t| MRN provided                  \t|\n",
    "| NEW_MRN       \t| New MRN (if updated)          \t|\n",
    "| PAT_ID        \t| Patient Identifier field      \t|\n",
    "| ORDER_MED_ID  \t| Medication order identifier # \t|\n",
    "| ORDERING_DATE \t| Date of order                 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data with Problems attached\n",
    "tmpfile = output+'/corrected_whoosh_data_withProblemList.csv'\n",
    "df_F = pd.read_csv(tmpfile, index_col=False)\n",
    "\n",
    "rows = df_F.PAT_ID[pd.isnull(df_F.PROBLEM_ID.values)]\n",
    "print(len(rows))\n",
    "\n",
    "df_6 = read_sheet(6)\n",
    "#Visualize Sheet\n",
    "df_6 = get_df_stats(df_6,['PAT_ID'])\n",
    "\n",
    "# Sort by Latest date for problem list\n",
    "df_6['ORDERING_DATE'] = pd.to_datetime(df_6.ORDERING_DATE)\n",
    "#df_6 = df_6.sort_values(by='ORDERING_DATE',ascending=False)\n",
    "#display(df_6.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_values_lower(in_val):\n",
    "    if isinstance(in_val,str):\n",
    "        return in_val.lower()\n",
    "    else:\n",
    "        out_val = [convert_values_lower(value) for value in in_val]\n",
    "        return out_val\n",
    "    \n",
    "def convert_dict_lower(in_dict):\n",
    "    out_dict = {}\n",
    "    for key,val in in_dict.items():\n",
    "        new_key = key.lower()\n",
    "        new_val = convert_values_lower(val)\n",
    "        out_dict[new_key] = new_val\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.search_terms_v5 import get_meds\n",
    "med_list = get_meds();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_list = convert_dict_lower(med_list)\n",
    "print(len(med_list.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_searchterms = list(itertools.chain(*med_list.values()))\n",
    "print('Number of problems: ', len(n_searchterms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of patients that are in the Medication list\n",
    "print(\"Number of patients in Master List: \")\n",
    "print(len(df_F))\n",
    "print(\"Number of patients in Medication List: \")\n",
    "med_pats = [pat_id for pat_id in df_F.PAT_ID if pat_id in df_6.PAT_ID.values]\n",
    "print(len(med_pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[\"MED_GROUP\"] = None\n",
    "df_F[\"MED_ID\"] = None\n",
    "df_F[\"MEDS\"] = None\n",
    "pat_ind = df_F.PAT_ID.isin(med_pats).values\n",
    "pat_ind_neg =~pat_ind\n",
    "df_F.loc[pat_ind_neg, 'MED_GROUP'] = 'no_meds'\n",
    "df_F.loc[pat_ind, 'MED_GROUP'] = 'unknown_meds'\n",
    "display(df_6.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for Med List search\n",
    "schema = Schema(mrn=ID(stored=True), content=TEXT(stored=True))\n",
    "\n",
    "# indexdir is a directory to store the search index\n",
    "im = create_in(output+'/whoosh', schema)\n",
    "\n",
    "writer = im.writer()\n",
    "\n",
    "for ind in df_6.index:\n",
    "    # add a document to search index that is keyed by MRN with the content being the problem list\n",
    "    problem = df_6.loc[ind,'MEDICATION_NAME']\n",
    "    route = df_6.loc[ind,'ROUTE']\n",
    "    pat_id = df_6.loc[ind,'PAT_ID']\n",
    "    #print(problem)\n",
    "    #break\n",
    "    if pd.isnull(route):\n",
    "        #print(problem,type(problem))\n",
    "        route = ''\n",
    "    if pd.isnull(problem):\n",
    "        #print(problem,type(problem))\n",
    "        problem = ''\n",
    "    problem = problem + ' ' + route\n",
    "    writer.add_document(\n",
    "    mrn=pat_id,\n",
    "    content=problem\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Query\n",
    "with im.searcher() as searcher:\n",
    "    # get all of the terms from the problem list and make term objects\n",
    "    #terms = [Term(\"content\", problem) for problem in itertools.chain.from_iterable(problem_list.values())]\n",
    "    for key,value in med_list.items():\n",
    "        terms = list()\n",
    "        for problem in value:\n",
    "            if isinstance(problem, str):\n",
    "                words = problem.split(' ')\n",
    "                if len(words) == 1:\n",
    "                   # print(problem)\n",
    "                    terms.append(Term(\"content\",problem))\n",
    "                else:\n",
    "                    word_t  = list()\n",
    "                    for word in words:\n",
    "                        word_t.append(Term(\"content\",word))\n",
    "                    terms.append(And(word_t))\n",
    "            else:\n",
    "                #print(problem)\n",
    "                terms.append(Term(\"content\",problem[0]) & Term(\"content\",problem[1]))\n",
    "        # Generates a query that will match cancer or lymphoma or neuroblastoma or ... and so on\n",
    "        query = Or(terms)\n",
    "       # query = QueryParser(\"content\", im.schema).parse(problem[0]+' '+problem[1])\n",
    "        results = searcher.search(query, terms=True, limit=None)\n",
    "        print(\"Group searched\", key)\n",
    "        print(results.estimated_length())\n",
    "        for i,hit in enumerate(results):\n",
    "            #print(i,hit['mrn'])\n",
    "            if hit['mrn'] in med_pats:\n",
    "               # print (hit['mrn'], ' ',df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'].values)\n",
    "               # print(hit['mrn'])\n",
    "               # print(','.join(map(str,[x[1] for x in hit.matched_terms()])))\n",
    "               # print(df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_ID'].values[0])\n",
    "               # print(df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_GROUP'].values[0])\n",
    "                if df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_GROUP'].values[0] == 'unknown_meds':\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_GROUP'] = key\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()]))\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'MEDS']  = hit['content']\n",
    "                else:\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_GROUP'] = key + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_GROUP'].values[0]\n",
    "                   # df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()])) + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'MED_ID'].values[0]\n",
    "                   # df_F.loc[df_F['PAT_ID']==hit['mrn'],'MEDS']  = hit['content'] + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'MEDS'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meds = df_F[(df_F['MED_GROUP']!='unknown_meds') & (df_F['MED_GROUP']!='no_meds')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_meds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.to_csv(output+'/corrected_whoosh_data_withProblemList_withMedList.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Read Sheet 3 - LDA\n",
    "\n",
    "| Field             \t| Field description                          \t|\n",
    "|-------------------\t|--------------------------------------------\t|\n",
    "| GIVEN_MRN         \t| MRN provided                               \t|\n",
    "| NEW_MRN           \t| New MRN (if updated)                       \t|\n",
    "| PAT_ID            \t| Patient Identifier field                   \t|\n",
    "| TYPE              \t| Type of log                                \t|\n",
    "| SURGERY_DATE      \t| Date of surgery                            \t|\n",
    "| CASE_SERVICE_NAME \t| Service name associated with surgical case \t|\n",
    "| DESCRIPTION       \t| Name/description of surgery                \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = read_sheet(3)\n",
    "#Visualize Sheet\n",
    "df_3 = get_df_stats(df_3,['PAT_ID'])\n",
    "display(df_3.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Latest date for problem list\n",
    "df_3['DATE_OF_ENTRY'] = pd.to_datetime(df_3.REMOVAL_DTTM)\n",
    "df_3 = df_3.sort_values(by='DATE_OF_ENTRY',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.search_terms_v5 import get_lda\n",
    "lda_list = get_lda();\n",
    "# Convert all terms to lower for Whoosh search\n",
    "lda_list = convert_dict_lower(lda_list)\n",
    "print(lda_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of patients that are in the Medication list\n",
    "print(\"Number of patients in Master List: \")\n",
    "print(len(df_F))\n",
    "print(\"Number of patients in LDA List: \")\n",
    "lda_pats = [pat_id for pat_id in df_F.PAT_ID if pat_id in df_3.PAT_ID.values]\n",
    "print(len(lda_pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[\"LDA_GROUP\"] = None\n",
    "df_F[\"LDA_ID\"] = None\n",
    "df_F[\"LDAS\"] = None\n",
    "pat_ind = df_F.PAT_ID.isin(lda_pats).values\n",
    "pat_ind_neg =~pat_ind\n",
    "df_F.loc[pat_ind_neg, 'LDA_GROUP'] = 'no_ldas'\n",
    "df_F.loc[pat_ind, 'LDA_GROUP'] = 'unknown_ldas'\n",
    "display(df_3.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for LDA List search\n",
    "schema = Schema(mrn=ID(stored=True), content=TEXT(stored=True))\n",
    "\n",
    "# indexdir is a directory to store the search index\n",
    "il = create_in(output+'/whoosh', schema)\n",
    "\n",
    "writer = il.writer()\n",
    "\n",
    "for ind in df_3.index:\n",
    "    # add a document to search index that is keyed by MRN with the content being the problem list\n",
    "    problem = df_3.loc[ind,'DESCRIPTION']\n",
    "    pat_id = df_3.loc[ind,'PAT_ID']\n",
    "    if pd.isnull(problem):\n",
    "        #print(problem,type(problem))\n",
    "        problem = ''\n",
    "    writer.add_document(\n",
    "    mrn=pat_id,\n",
    "    content=problem\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Query\n",
    "with il.searcher() as searcher:\n",
    "    # get all of the terms from the problem list and make term objects\n",
    "    #terms = [Term(\"content\", problem) for problem in itertools.chain.from_iterable(problem_list.values())]\n",
    "    for key,value in lda_list.items():\n",
    "        terms = list()\n",
    "        for problem in value:\n",
    "            if isinstance(problem, str):\n",
    "                words = problem.split(' ')\n",
    "                if len(words) == 1:\n",
    "                   # print(problem)\n",
    "                    terms.append(Term(\"content\",problem))\n",
    "                else:\n",
    "                    word_t  = list()\n",
    "                    for word in words:\n",
    "                        word_t.append(Term(\"content\",word))\n",
    "                    terms.append(And(word_t))\n",
    "            else:\n",
    "                #print(problem)\n",
    "                terms.append(Term(\"content\",problem[0]) & Term(\"content\",problem[1]))\n",
    "        # Generates a query that will match cancer or lymphoma or neuroblastoma or ... and so on\n",
    "        query = Or(terms)\n",
    "       # query = QueryParser(\"content\", im.schema).parse(problem[0]+' '+problem[1])\n",
    "        results = searcher.search(query, terms=True, limit=None)\n",
    "        print(\"Group searched\", key)\n",
    "        print(results.estimated_length())\n",
    "        for hit in results:\n",
    "            if hit['mrn'] in lda_pats:\n",
    "               # print (hit['mrn'], ' ',df_F.loc[df_F['PAT_ID']==hit['mrn'],'PROBLEM_GROUP'].values)\n",
    "               # print(hit['mrn'])\n",
    "               # print(','.join(map(str,[x[1] for x in hit.matched_terms()])))\n",
    "               # print(df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_ID'].values[0])\n",
    "               # print(df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_GROUP'].values[0])\n",
    "                if df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_GROUP'].values[0] == 'unknown_ldas':\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_GROUP'] = key\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()]))\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDAS']  = hit['content']\n",
    "                else:\n",
    "                    df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_GROUP'] = key + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_GROUP'].values[0]\n",
    "                  #  df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_ID'] = ','.join(map(str,[x[1] for x in hit.matched_terms()])) + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDA_ID'].values[0]\n",
    "                  #  df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDAS']  = hit['content'] + ',' + df_F.loc[df_F['PAT_ID']==hit['mrn'],'LDAS'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.to_csv(output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile  = output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA.csv'\n",
    "#infile  = output+'/corrected_whoosh_data.csv'\n",
    "df_F = pd.read_csv(infile, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 5: Read Sheet 9 - Surgeries\n",
    "\n",
    "| Field             \t| Field description                          \t|\n",
    "|-------------------\t|--------------------------------------------\t|\n",
    "| GIVEN_MRN         \t| MRN provided                               \t|\n",
    "| NEW_MRN           \t| New MRN (if updated)                       \t|\n",
    "| PAT_ID            \t| Patient Identifier field                   \t|\n",
    "| TYPE              \t| Type of log                                \t|\n",
    "| SURGERY_DATE      \t| Date of surgery                            \t|\n",
    "| CASE_SERVICE_NAME \t| Service name associated with surgical case \t|\n",
    "| DESCRIPTION       \t| Name/description of surgery                \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9 = read_sheet(9)\n",
    "#Visualize Sheet\n",
    "df_9 = get_df_stats(df_9,['PAT_ID'])\n",
    "\n",
    "# Sort by Latest date for problem list\n",
    "df_9['SURGERY_DATE'] = pd.to_datetime(df_9.SURGERY_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_9.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of patients that are in the Surgery list\n",
    "print(\"Number of patients in Master List: \")\n",
    "print(len(df_F))\n",
    "print(\"Number of patients in Surgery List: \")\n",
    "surg_pats = [pat_id for pat_id in df_F.PAT_ID if pat_id in df_9.PAT_ID.values]\n",
    "print(len(surg_pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F[\"SURGERY\"] = None\n",
    "df_F[\"SURGERY_to_Imaging_days\"] = 'no_date'\n",
    "df_F['CT_SCAN_DATE'] = pd.to_datetime(df_F.CT_SCAN_DATE)\n",
    "pat_ind = df_F.PAT_ID.isin(surg_pats).values\n",
    "pat_ind_neg =~pat_ind\n",
    "df_F.loc[pat_ind_neg, 'SURGERY'] = 'no_surgery'\n",
    "df_F.loc[pat_ind, 'SURGERY'] = 'surgery'\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat_id in surg_pats:\n",
    "        #print(pat_id)\n",
    "        scan_date = df_F.loc[df_F['PAT_ID']==pat_id, 'CT_SCAN_DATE']\n",
    "        rows = df_9.loc[df_9['PAT_ID']==pat_id]\n",
    "        rows = rows.sort_values(by='SURGERY_DATE',ascending=False)\n",
    "        surgery_dates = rows.SURGERY_DATE.values\n",
    "        for surgery_date in surgery_dates:\n",
    "            #print('Scan date: ',scan_date)\n",
    "            datediff = abs(scan_date - surgery_date).astype('timedelta64[D]').iloc[0]\n",
    "            #print(datediff)\n",
    "            if datediff > 30:\n",
    "                df_F.loc[df_F['PAT_ID']==pat_id, 'SURGERY_to_Imaging_days'] = '> 30'\n",
    "            else:\n",
    "                df_F.loc[df_F['PAT_ID']==pat_id, 'SURGERY_to_Imaging_days'] = '<= 30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.to_csv(output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA_withSurgery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Read Sheet 10 - Surgical History\n",
    "\n",
    "| Field             \t| Field description                          \t|\n",
    "|-------------------\t|--------------------------------------------\t|\n",
    "| GIVEN_MRN         \t| MRN provided                               \t|\n",
    "| NEW_MRN           \t| New MRN (if updated)                       \t|\n",
    "| PAT_ID            \t| Patient Identifier field                   \t|\n",
    "| PROCEDURE         \t| Surgery Performed                          \t|\n",
    "| SURGICAL_HX_DATE  \t| Date of surgery                            \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Previously Saved file from epic_filter_1: \n",
    "tmpfile = output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA_withSurgery.csv'\n",
    "df_F = pd.read_csv(tmpfile, index_col=False)\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = read_sheet(10)\n",
    "#Visualize Sheet\n",
    "df_10 = get_df_stats(df_10,['PAT_ID','SURGICAL_HX_DATE'])\n",
    "\n",
    "# Sort by Latest date for problem list\n",
    "df_10['SURGICAL_HX_DATE'] = pd.to_datetime(df_10.SURGICAL_HX_DATE,errors='coerce')\n",
    "display(df_10.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of patients that are in the Surgery History\n",
    "print(\"Number of patients in Master List: \")\n",
    "print(len(df_F))\n",
    "print(\"Number of patients in Surgery History List: \")\n",
    "surghx_pats = [pat_id for pat_id in df_F.PAT_ID if pat_id in df_10.PAT_ID.values]\n",
    "print(len(surghx_pats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F['CT_SCAN_DATE'] = pd.to_datetime(df_F.CT_SCAN_DATE)\n",
    "for pat_id in surghx_pats:\n",
    "        #print(pat_id)\n",
    "        rows = df_10.loc[df_10['PAT_ID']==pat_id]\n",
    "        rows = rows.sort_values(by='SURGICAL_HX_DATE',ascending=False)\n",
    "        surgery_dates = rows.SURGICAL_HX_DATE.values\n",
    "        for surgery_date in surgery_dates:\n",
    "            #print('Scan date: ',scan_date)\n",
    "            datediff = abs(scan_date - surgery_date).astype('timedelta64[D]').iloc[0]\n",
    "            #print(datediff)\n",
    "            if datediff > 30:\n",
    "                df_F.loc[df_F['PAT_ID']==pat_id, 'SURGERY_to_Imaging_days'] = '> 30'\n",
    "            else:\n",
    "                df_F.loc[df_F['PAT_ID']==pat_id, 'SURGERY_to_Imaging_days'] = '<= 30'\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F.to_csv(output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA_withSurgery_withSurgHX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Select Patients\n",
    "\n",
    "Filter by Surgery, Problem_list and Meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile  = output+'/corrected_whoosh_data_withProblemList_withMedList_withLDA_withSurgery_withSurgHX.csv'\n",
    "#infile  = output+'/corrected_whoosh_data.csv'\n",
    "df_F = pd.read_csv(infile, index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F['ValidPatient'] = 0\n",
    "df_F.loc[df_F.PROBLEM_GROUP.isin(['unknown_problem','no_problem']) &\n",
    "         df_F.MED_GROUP.isin(['unknown_meds','no_meds']) &\n",
    "         df_F.LDA_GROUP.isin(['unknown_ldas','no_ldas']) &\n",
    "         df_F.SURGERY_to_Imaging_days.isin(['no_date','> 30']), 'ValidPatient'] = 1\n",
    "\n",
    "display(df_F.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_F = df_F.sort_values(by=['ValidPatient'],ascending=False)\n",
    "validPats = df_F.PAT_ID[df_F.ValidPatient==1]\n",
    "invalidPats = df_F.PAT_ID[df_F.ValidPatient==0]\n",
    "print(len(validPats))\n",
    "print(len(invalidPats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_F[df_F.ValidPatient==1]\n",
    "df_valid.to_csv(output+'/corrected_whoosh_data_validpatients_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
